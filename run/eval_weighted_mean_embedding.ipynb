{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4857dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os, sys\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b614af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        rst=pickle.load(f)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fe8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml/full_id_abs_title_cite_ref_author.pkl\"\n",
    "full_data=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/eval_rerank/test_result/eval_key_id2embed.pkl\"\n",
    "key_embedding=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fb80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_test_pred_1000.pkl\"\n",
    "pred_set=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_test_gold.pkl\"\n",
    "gold_set=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33819b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id2embedding=key_embedding\n",
    "key_id2embedding=key_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b5144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_set={}\n",
    "candidate_ref_set={}\n",
    "for k,v in pred_set.items():\n",
    "    cur=set()\n",
    "    for paper in v[:200]:\n",
    "        cur.add(paper)\n",
    "        refset=set()\n",
    "        for ref in full_data[paper][\"references\"]:\n",
    "            cur.add(ref)\n",
    "            refset.add(ref)\n",
    "        candidate_ref_set[paper]=refset\n",
    "    candidate_set[k]=list(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b9e03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_weighted_mean(full_data,candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        \n",
    "        cited_dict={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            \n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cited_dict.keys():\n",
    "                            cited_dict[ref]=[candidate]\n",
    "                        else:\n",
    "                            cited_dict[ref].append(candidate)\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cited_dict.keys():\n",
    "                cited_dict[candidate]=[candidate]\n",
    "            else:\n",
    "                cited_dict[candidate].append(candidate)\n",
    "                \n",
    "                \n",
    "        key_embedding=[]\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            candidate_embedding=[]\n",
    "            total_weight=1\n",
    "            for paper in cited_dict[candidate]:\n",
    "                if paper in key_id2embedding:\n",
    "                    weight=full_data[paper]['citationCount']\n",
    "                    total_weight+= weight\n",
    "                    candidate_embedding.append(weight*torch.tensor(key_id2embedding[paper]))\n",
    "            if len(candidate_embedding)==0:\n",
    "                candidate_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "            candidate_embedding=torch.sum(torch.stack(candidate_embedding),dim=0)/total_weight\n",
    "            \n",
    "            key_embedding.append(candidate_embedding)\n",
    "        \n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc68e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_weighted_mean(full_data,candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        \n",
    "        cited_dict={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            \n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cited_dict.keys():\n",
    "                            cited_dict[ref]=[candidate]\n",
    "                        else:\n",
    "                            cited_dict[ref].append(candidate)\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cited_dict.keys():\n",
    "                cited_dict[candidate]=[candidate]\n",
    "            else:\n",
    "                cited_dict[candidate].append(candidate)\n",
    "                \n",
    "                \n",
    "        key_embedding=[]\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            candidate_embedding=[]\n",
    "            total_weight=1\n",
    "            for paper in cited_dict[candidate]:\n",
    "                if paper in key_id2embedding:\n",
    "                    weight=full_data[paper]['citationCount']\n",
    "                    total_weight+= weight\n",
    "                    candidate_embedding.append(weight*torch.tensor(key_id2embedding[paper]))\n",
    "            if len(candidate_embedding)==0:\n",
    "                candidate_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "            candidate_embedding=torch.sum(torch.stack(candidate_embedding),dim=0)/total_weight\n",
    "\n",
    "            key_embedding.append(candidate_embedding)\n",
    "        \n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4814628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_candidate=rerank_weighted_mean(full_data,candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b1a30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/share/data/mei-work/kangrui/github/ssref\")\n",
    "from utils.test_utils import *\n",
    "from utils.utils import *\n",
    "def show_rerank_rst(rerank_candidate,gold_set):\n",
    "    pool_length=len(next(iter(rerank_candidate.values())))\n",
    "    i=2\n",
    "    while 1:\n",
    "        all_pred_topN=[]\n",
    "        all_gold=[]\n",
    "        for query_paper,paperlist in rerank_candidate.items():\n",
    "            topN=paperlist[:i]\n",
    "            all_pred_topN.append(topN)\n",
    "            all_gold.append(gold_set[query_paper])\n",
    "        all_pred_topN=np.array(all_pred_topN)\n",
    "        metric = get_precision_recall_f1(all_pred_topN, all_gold)\n",
    "        print(f\"top{i}:\\n{metric}\")\n",
    "        if i>pool_length:\n",
    "            break\n",
    "        i*=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e69f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top2:\n",
      "{'precision': 0.1027542372881356, 'recall': 0.005046826222684703, 'f1': 0.009621106923229516, 'true_pos': 194, 'false_pos': 1694, 'false_neg': 38246, 'num_sample': 944}\n",
      "top4:\n",
      "{'precision': 0.08501059322033898, 'recall': 0.008350676378772112, 'f1': 0.015207504263786241, 'true_pos': 321, 'false_pos': 3455, 'false_neg': 38119, 'num_sample': 944}\n",
      "top8:\n",
      "{'precision': 0.0791843220338983, 'recall': 0.015556711758584807, 'f1': 0.026004522525656635, 'true_pos': 598, 'false_pos': 6954, 'false_neg': 37842, 'num_sample': 944}\n",
      "top16:\n",
      "{'precision': 0.06951800847457627, 'recall': 0.027315296566077004, 'f1': 0.03922008068130883, 'true_pos': 1050, 'false_pos': 14054, 'false_neg': 37390, 'num_sample': 944}\n",
      "top32:\n",
      "{'precision': 0.06173861228813559, 'recall': 0.04851716961498439, 'f1': 0.05433515907236918, 'true_pos': 1865, 'false_pos': 28343, 'false_neg': 36575, 'num_sample': 944}\n",
      "top64:\n",
      "{'precision': 0.052932997881355935, 'recall': 0.0831945889698231, 'f1': 0.0647001699441612, 'true_pos': 3198, 'false_pos': 57218, 'false_neg': 35242, 'num_sample': 944}\n",
      "top128:\n",
      "{'precision': 0.0436473781779661, 'recall': 0.13720083246618106, 'f1': 0.06622632980059269, 'true_pos': 5274, 'false_pos': 115558, 'false_neg': 33166, 'num_sample': 944}\n",
      "top256:\n",
      "{'precision': 0.03329829846398305, 'recall': 0.20933922996878251, 'f1': 0.057457230171650525, 'true_pos': 8047, 'false_pos': 233617, 'false_neg': 30393, 'num_sample': 944}\n",
      "top512:\n",
      "{'precision': 0.023832676774364406, 'recall': 0.2996618106139438, 'f1': 0.044153723493966665, 'true_pos': 11519, 'false_pos': 471809, 'false_neg': 26921, 'num_sample': 944}\n",
      "top1024:\n",
      "{'precision': 0.016305697166313558, 'recall': 0.4100416233090531, 'f1': 0.031364168198858615, 'true_pos': 15762, 'false_pos': 950894, 'false_neg': 22678, 'num_sample': 944}\n",
      "top2048:\n",
      "{'precision': 0.011637417203703537, 'recall': 0.540426638917794, 'f1': 0.022784204823135604, 'true_pos': 20774, 'false_pos': 1764330, 'false_neg': 17666, 'num_sample': 944}\n"
     ]
    }
   ],
   "source": [
    "show_rerank_rst(rerank_candidate,gold_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
