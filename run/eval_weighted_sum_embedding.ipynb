{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4857dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os, sys\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b614af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        rst=pickle.load(f)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fe8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml/full_id_abs_title_cite_ref_author.pkl\"\n",
    "full_data=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/eval_rerank/test_result/eval_key_id2embed.pkl\"\n",
    "key_embedding=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fb80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_test_pred_1000.pkl\"\n",
    "pred_set=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_test_gold.pkl\"\n",
    "gold_set=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33819b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id2embedding=key_embedding\n",
    "key_id2embedding=key_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b5144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_set={}\n",
    "candidate_ref_set={}\n",
    "for k,v in pred_set.items():\n",
    "    cur=set()\n",
    "    for paper in v[:200]:\n",
    "        cur.add(paper)\n",
    "        refset=set()\n",
    "        for ref in full_data[paper][\"references\"]:\n",
    "            cur.add(ref)\n",
    "            refset.add(ref)\n",
    "        candidate_ref_set[paper]=refset\n",
    "    candidate_set[k]=list(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9e03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_weighted_sum(full_data,candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        \n",
    "        cited_dict={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            \n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cited_dict.keys():\n",
    "                            cited_dict[ref]=[candidate]\n",
    "                        else:\n",
    "                            cited_dict[ref].append(candidate)\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cited_dict.keys():\n",
    "                cited_dict[candidate]=[candidate]\n",
    "            else:\n",
    "                cited_dict[candidate].append(candidate)\n",
    "                \n",
    "                \n",
    "        key_embedding=[]\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            candidate_embedding=[]\n",
    "            total_weight=1\n",
    "            for paper in cited_dict[candidate]:\n",
    "                if paper in key_id2embedding:\n",
    "                    weight=full_data[paper]['citationCount']\n",
    "                    total_weight+= weight\n",
    "                    candidate_embedding.append(weight*torch.tensor(key_id2embedding[paper]))\n",
    "            if len(candidate_embedding)==0:\n",
    "                candidate_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "            candidate_embedding=torch.sum(torch.stack(candidate_embedding),dim=0)/total_weight\n",
    "            \n",
    "            key_embedding.append(candidate_embedding)\n",
    "        \n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d23a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_weighted(full_data,candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        \n",
    "        cited_dict={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            \n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cited_dict.keys():\n",
    "                            cited_dict[ref]=[candidate]\n",
    "                        else:\n",
    "                            cited_dict[ref].append(candidate)\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cited_dict.keys():\n",
    "                cited_dict[candidate]=[candidate]\n",
    "            else:\n",
    "                cited_dict[candidate].append(candidate)\n",
    "                \n",
    "                \n",
    "        key_embedding=[]\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            candidate_embedding=[]\n",
    "            total_weight=1\n",
    "            for paper in cited_dict[candidate]:\n",
    "                if paper in key_id2embedding:\n",
    "                    weight=full_data[paper]['citationCount']\n",
    "                    total_weight+= weight\n",
    "                    candidate_embedding.append(weight*torch.tensor(key_id2embedding[paper]))\n",
    "            if len(candidate_embedding)==0:\n",
    "                candidate_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "            candidate_embedding=torch.sum(torch.stack(candidate_embedding),dim=0)\n",
    "            \n",
    "            key_embedding.append(candidate_embedding)\n",
    "        \n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4814628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66aeaf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 944/944 [06:59<00:00,  2.25it/s, calculating f1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty embedding cnt-> 0\n",
      "min rerank num-> 1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rerank_candidate=rerank_weighted_sum(full_data,candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e9bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/share/data/mei-work/kangrui/github/ssref\")\n",
    "from utils.test_utils import *\n",
    "from utils.utils import *\n",
    "def show_rerank_rst(rerank_candidate,gold_set):\n",
    "    pool_length=len(next(iter(rerank_candidate.values())))\n",
    "    i=2\n",
    "    while 1:\n",
    "        all_pred_topN=[]\n",
    "        all_gold=[]\n",
    "        for query_paper,paperlist in rerank_candidate.items():\n",
    "            topN=paperlist[:i]\n",
    "            all_pred_topN.append(topN)\n",
    "            all_gold.append(gold_set[query_paper])\n",
    "        all_pred_topN=np.array(all_pred_topN)\n",
    "        metric = get_precision_recall_f1(all_pred_topN, all_gold)\n",
    "        print(f\"top{i}:\\n{metric}\")\n",
    "        if i>pool_length:\n",
    "            break\n",
    "        i*=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55456001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top2:\n",
      "{'precision': 0.10434322033898305, 'recall': 0.005124869927159209, 'f1': 0.009769886927196984, 'true_pos': 197, 'false_pos': 1691, 'false_neg': 38243, 'num_sample': 944}\n",
      "top4:\n",
      "{'precision': 0.0847457627118644, 'recall': 0.008324661810613945, 'f1': 0.01516012886109532, 'true_pos': 320, 'false_pos': 3456, 'false_neg': 38120, 'num_sample': 944}\n",
      "top8:\n",
      "{'precision': 0.07971398305084745, 'recall': 0.01566077003121748, 'f1': 0.026178465820142632, 'true_pos': 602, 'false_pos': 6950, 'false_neg': 37838, 'num_sample': 944}\n",
      "top16:\n",
      "{'precision': 0.0697166313559322, 'recall': 0.02739334027055151, 'f1': 0.039332138054683996, 'true_pos': 1053, 'false_pos': 14051, 'false_neg': 37387, 'num_sample': 944}\n",
      "top32:\n",
      "{'precision': 0.06197033898305085, 'recall': 0.04869927159209157, 'f1': 0.05453909800722526, 'true_pos': 1872, 'false_pos': 28336, 'false_neg': 36568, 'num_sample': 944}\n",
      "top64:\n",
      "{'precision': 0.05334679555084746, 'recall': 0.08384495317377731, 'f1': 0.06520595613822125, 'true_pos': 3223, 'false_pos': 57193, 'false_neg': 35217, 'num_sample': 944}\n",
      "top128:\n",
      "{'precision': 0.04378806938559322, 'recall': 0.13764308012486992, 'f1': 0.06643980109498218, 'true_pos': 5291, 'false_pos': 115541, 'false_neg': 33149, 'num_sample': 944}\n",
      "top256:\n",
      "{'precision': 0.03321553893008475, 'recall': 0.20881893860561915, 'f1': 0.05731442607031674, 'true_pos': 8027, 'false_pos': 233637, 'false_neg': 30413, 'num_sample': 944}\n",
      "top512:\n",
      "{'precision': 0.023754055217161018, 'recall': 0.2986732570239334, 'f1': 0.04400806488707625, 'true_pos': 11481, 'false_pos': 471847, 'false_neg': 26959, 'num_sample': 944}\n",
      "top1024:\n",
      "{'precision': 0.016312938625529662, 'recall': 0.41022372528616025, 'f1': 0.031378097216584286, 'true_pos': 15769, 'false_pos': 950887, 'false_neg': 22671, 'num_sample': 944}\n",
      "top2048:\n",
      "{'precision': 0.011626213374682932, 'recall': 0.5399063475546306, 'f1': 0.022762269514747108, 'true_pos': 20754, 'false_pos': 1764350, 'false_neg': 17686, 'num_sample': 944}\n"
     ]
    }
   ],
   "source": [
    "show_rerank_rst(rerank_candidate,gold_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec3278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
