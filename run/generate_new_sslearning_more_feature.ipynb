{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1e8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os, sys\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fd19e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936a8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        rst=pickle.load(f)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7688670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumppkl(data,path):\n",
    "    with open(path,'wb') as f:\n",
    "        pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28787438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_and_txt(train_data,full_data):\n",
    "    cite_pair=[]\n",
    "    cite2txt_abs_title_author={}\n",
    "    for k,v in train_data.items():\n",
    "        data={}\n",
    "        data['paperID']=k\n",
    "        if full_data[k]['abstract'] is not None:\n",
    "            data['abstract']=full_data[k]['abstract']\n",
    "        else:\n",
    "            data['abstract']=\"\"\n",
    "        if full_data[k]['title'] is not None:\n",
    "            data['title']=full_data[k]['title']\n",
    "        else:\n",
    "            data['title']=\"\"\n",
    "        data['authors']=full_data[k]['authors']\n",
    "        cite2txt_abs_title_author[k]=data\n",
    "        for pred in v:\n",
    "            dp={}\n",
    "            dp['query']=k\n",
    "            dp['key']=pred\n",
    "            dp['value']=get_cover_paper(k,pred,full_data)\n",
    "            cite_pair.append(dp)\n",
    "\n",
    "            data={}\n",
    "            data['paperID']=pred\n",
    "            if full_data[pred]['abstract'] is not None:\n",
    "                data['abstract']=full_data[pred]['abstract']\n",
    "            else:\n",
    "                data['abstract']=\"\"\n",
    "            if full_data[pred]['title'] is not None:\n",
    "                data['title']=full_data[pred]['title']\n",
    "            else:\n",
    "                data['title']=\"\"\n",
    "            data['authors']=full_data[pred]['authors']\n",
    "            cite2txt_abs_title_author[pred]=data\n",
    "    return cite_pair,cite2txt_abs_title_author\n",
    "\n",
    "def get_pair_and_info(train_data,full_data):\n",
    "    cite_pair=[]\n",
    "    cite2txt_abs_title_author={}\n",
    "    for k,v in train_data.items():\n",
    "        data={}\n",
    "        data['paperID']=k\n",
    "        if full_data[k]['abstract'] is not None:\n",
    "            data['abstract']=full_data[k]['abstract']\n",
    "        else:\n",
    "            data['abstract']=\"\"\n",
    "        if full_data[k]['title'] is not None:\n",
    "            data['title']=full_data[k]['title']\n",
    "        else:\n",
    "            data['title']=\"\"\n",
    "        data['authors']=full_data[k]['authors']\n",
    "        data['references']=full_data[k]['references']\n",
    "        cite2txt_abs_title_author[k]=data\n",
    "        for pred in v:\n",
    "            dp={}\n",
    "            dp['query']=k\n",
    "            dp['key']=pred\n",
    "            dp['value']=get_cover_paper(k,pred,full_data)\n",
    "            cite_pair.append(dp)\n",
    "\n",
    "            data={}\n",
    "            data['paperID']=pred\n",
    "            if full_data[pred]['abstract'] is not None:\n",
    "                data['abstract']=full_data[pred]['abstract']\n",
    "            else:\n",
    "                data['abstract']=\"\"\n",
    "            if full_data[pred]['title'] is not None:\n",
    "                data['title']=full_data[pred]['title']\n",
    "            else:\n",
    "                data['title']=\"\"\n",
    "            data['authors']=full_data[pred]['authors']\n",
    "            data['references']=full_data[pred]['references']\n",
    "            cite2txt_abs_title_author[pred]=data\n",
    "    return cite_pair,cite2txt_abs_title_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960b26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cover_paper(query,key,full_data):\n",
    "    query_ref=set([paper['paperId'] for paper in full_data[query]['references']])\n",
    "    key_ref=set([paper['paperId'] for paper in full_data[key]['references']])\n",
    "    key_ref.add(key)\n",
    "    cover_num=len(query_ref&key_ref)\n",
    "    return cover_num\n",
    "def calculate_cite_info(train_data,full_data):\n",
    "    cite_pair=[]\n",
    "    for k,v in train_data.items():\n",
    "        for pred in v:\n",
    "            cite_pair.append(get_cover_paper(k,pred,full_data))\n",
    "    cite_pair=np.array(cite_pair)\n",
    "    print(np.sum(cite_pair==0))\n",
    "    print(len(cite_pair))\n",
    "    print(np.mean(cite_pair))\n",
    "    return cite_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6057bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml/full_data_no_embed.pkl\"\n",
    "full_data=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cad9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_train_pred_1000.pkl\"\n",
    "train_data=loadpkl(path)\n",
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_dev_pred_1000.pkl\"\n",
    "dev_data=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "300934e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_pair,cite2txt_abs_title_author=get_pair_and_txt(train_data,full_data)\n",
    "path1=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/train_top1000_cite_pair.pkl\"\n",
    "path2=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/train_top1000_cite2txt_abs_title_author.pkl\"\n",
    "dumppkl(cite_pair,path1)\n",
    "dumppkl(cite2txt_abs_title_author,path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d928d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5447476206857012\n"
     ]
    }
   ],
   "source": [
    "len(cite_pair)\n",
    "rst=[]\n",
    "for dp in cite_pair:\n",
    "    rst.append(dp['value'])\n",
    "print(np.mean(rst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8e4c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_pair,cite2txt_abs_title_author_ref=get_pair_and_info(dev_data,full_data)\n",
    "path1=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/dev_top1000_cite_pair.pkl\"\n",
    "path2=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/dev_top1000_cite2txt_abs_title_author_ref.pkl\"\n",
    "dumppkl(cite_pair,path1)\n",
    "dumppkl(cite2txt_abs_title_author_ref,path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce792d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cd46a80ce754dfa497e46477f9589e81b9ac9df4',\n",
       " {'paperID': 'cd46a80ce754dfa497e46477f9589e81b9ac9df4',\n",
       "  'abstract': 'Automated Guided Vehicles (AGVs) have been widely used for material handling in flexible shop floors. Each product requires various raw materials to complete the assembly in production process. AGVs are used to realize the automatic handling of raw materials in different locations. Efficient AGVs task allocation strategy can reduce transportation costs and improve distribution efficiency. However, the traditional centralized approaches make high demands on the control centerâ€™s computing power and real-time capability. In this paper, we present decentralized solutions to achieve flexible and self-organized AGVs task allocation. In particular, we propose two improved multi-agent reinforcement learning algorithms, MAD-DPG-IPF (Information Potential Field) and BiCNet-IPF, to realize the coordination among AGVs adapting to different scenarios. To address the reward-sparsity issue, we propose a reward shaping strategy based on information potential field, which provides stepwise rewards and implicitly guides the AGVs to different material targets. We conduct experiments under different settings (3 AGVs and 6 AGVs), and the experiment results indicate that, compared with baseline methods, our work obtains up to 47% task response improvement and 22% training iterations reduction.',\n",
       "  'title': 'Decentralized Multi-AGV Task Allocation based on Multi-Agent Reinforcement Learning with Information Potential Field Rewards',\n",
       "  'authors': [{'authorId': '2145711930', 'name': 'Mengyuan Li'},\n",
       "   {'authorId': '145066132', 'name': 'Bin Guo'},\n",
       "   {'authorId': '2155240997', 'name': 'Jiangshan Zhang'},\n",
       "   {'authorId': '2108380767', 'name': 'Jiaqi Liu'},\n",
       "   {'authorId': '2155857286', 'name': 'Sicong Liu'},\n",
       "   {'authorId': '2256618', 'name': 'Zhiwen Yu'},\n",
       "   {'authorId': '3208023', 'name': 'Zhetao Li'},\n",
       "   {'authorId': '1850278', 'name': 'Liyao Xiang'}],\n",
       "  'references': [{'paperId': '049e95a778eb597baebfe1569bab1e16b8badd00',\n",
       "    'title': 'AGV Task Distribution Study'},\n",
       "   {'paperId': '30e02b6278fc5d46354dd838cbf63b2eac680c06',\n",
       "    'title': 'A proactive material handling method for CPS enabled shop-floor'},\n",
       "   {'paperId': '28e66d188efbd0bbb64242b611d96769be910c15',\n",
       "    'title': 'Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications'},\n",
       "   {'paperId': None,\n",
       "    'title': 'AGV Task Distribution Study[C]//Journal of Physics: Conference Series'},\n",
       "   {'paperId': None,\n",
       "    'title': 'Deep reinforcement learning for multiagent systems: A review of challenges, solutions, and applications[J'},\n",
       "   {'paperId': '998b539c7137b180bffa4a68b81cec90cf29578e',\n",
       "    'title': 'Multi-objective AGV scheduling in an automatic sorting system of an unmanned (intelligent) warehouse by using two adaptive genetic algorithms and a multi-adaptive genetic algorithm'},\n",
       "   {'paperId': 'f7c15e9ac6653330b7dd18a89301a3b333927db3',\n",
       "    'title': 'A Review of Cooperative Multi-Agent Deep Reinforcement Learning'},\n",
       "   {'paperId': '8fc03c69fca1b6a3ad1666ad7fb5f1ad822e35a1',\n",
       "    'title': 'Multiagent and Bargaining-Game-Based Real-Time Scheduling for Internet of Things-Enabled Flexible Job Shop'},\n",
       "   {'paperId': '4d79f94fd08a935012b31a9c66e0ccab9adb050d',\n",
       "    'title': 'A big data driven analytical framework for energy-intensive manufacturing industries'},\n",
       "   {'paperId': 'b6cc894aa0c029a566d983d8f95d3502a62aee33',\n",
       "    'title': 'An Improved Particle Swarm Optimization Algorithm for Integrated Scheduling Model in AGV-Served Manufacturing Systems'},\n",
       "   {'paperId': '33603f482555027251c4f192f596b57b3a39ae49',\n",
       "    'title': 'Decentralized Motion Planning and Scheduling of AGVs in an FMS'},\n",
       "   {'paperId': '2b292ff89d808fba10579871591a22f1649cd039',\n",
       "    'title': 'Counterfactual Multi-Agent Policy Gradients'},\n",
       "   {'paperId': None,\n",
       "    'title': 'A big data driven analytical framework for energy-intensive manufacturing industries[J'},\n",
       "   {'paperId': None,\n",
       "    'title': 'An improved particle swarm optimization algorithm for integrated scheduling model in AGV-served manufacturing systems[J'},\n",
       "   {'paperId': None, 'title': 'Counterfactual multi-agent policy'},\n",
       "   {'paperId': '99cdeebb2bcdc96feb8269ce72235553ae341e3c',\n",
       "    'title': 'Gradient-driven parking navigation using a continuous information potential field based on wireless sensor network'},\n",
       "   {'paperId': '6127b8dc39497a2388a0fce2512595e0dcb7121b',\n",
       "    'title': 'StarCraft II: A New Challenge for Reinforcement Learning'},\n",
       "   {'paperId': 'e2726847b7ebb335bdd390eb55a36043579c148c',\n",
       "    'title': 'Energy-Efficient Algorithm to Construct the Information Potential Field in WSNs'},\n",
       "   {'paperId': '7c3ece1ba41c415d7e81cfa5ca33a8de66efd434',\n",
       "    'title': 'Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments'},\n",
       "   {'paperId': '8155c2f9b81c24f40a216508f3415348eedaca9a',\n",
       "    'title': 'Multirobot task allocation based on an improved particle swarm optimization approach'},\n",
       "   {'paperId': '76dfb1ab698963f3776fe894b3743db4a5419a5f',\n",
       "    'title': 'Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games'},\n",
       "   {'paperId': 'c4e1d0ab70d145a49095cfb459dd37878dae306d',\n",
       "    'title': 'Multi-objective AGV scheduling in an FMS using a hybrid of genetic algorithm and particle swarm optimization'},\n",
       "   {'paperId': '3ac0fea1e5395cfb0dc1f0ee2b921fe22b23fed0',\n",
       "    'title': 'Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning'},\n",
       "   {'paperId': '7f2369f7b1251d07d1ece37e40a520a8dfe46992',\n",
       "    'title': 'An Ant Colony Algorithm (ACA) for solving the new integrated model of job shop scheduling and conflict-free routing of AGVs'},\n",
       "   {'paperId': 'e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d',\n",
       "    'title': 'Human-level control through deep reinforcement learning'},\n",
       "   {'paperId': 'ed65a6529e158c1402ea6bdeb679f5654ba33584',\n",
       "    'title': 'Multi-robot Task Allocation: A Review of the State-of-the-Art'},\n",
       "   {'paperId': None,\n",
       "    'title': 'An Ant Colony Algorithm (ACA) for solving the new integrated model of job shop scheduling and conflict-free routing of AGVs[J'},\n",
       "   {'paperId': 'e29531b07b78a9dcb21a4801c4ef0cd12487a9b7',\n",
       "    'title': 'Cooperative Robots and Sensor Networks'},\n",
       "   {'paperId': 'a2fa34721c24a23c41b0a52ed8666c0abd290413',\n",
       "    'title': 'Information Potential Fields Navigation in Wireless Ad-Hoc Sensor Networks'},\n",
       "   {'paperId': '7f2e2803543b61f83df9ec709a330c5c710d709b',\n",
       "    'title': 'Composable Information Gradients in Wireless Sensor Networks'},\n",
       "   {'paperId': '8338432a58b21d77ed17a393f0c09acd63da3397',\n",
       "    'title': 'Research on integrated navigation method for AUV'},\n",
       "   {'paperId': 'e23c34414e66118ecd9b08cf0cd4d016f59b0b85',\n",
       "    'title': 'Bidirectional recurrent neural networks'},\n",
       "   {'paperId': None, 'title': 'Bidirectional recurrent neural networks[J'},\n",
       "   {'paperId': None,\n",
       "    'title': 'Multi-agent reinforcement learning: Independent vs. cooperative agents[C]//Proceedings of the tenth international conference on machine learning'},\n",
       "   {'paperId': None,\n",
       "    'title': 'Multi-agent reinforcement learning: Independent vs'}]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cite2txt_abs_title_author_ref.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1de38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_pair,cite2txt_abs_title_author=get_pair_and_txt(dev_data,full_data)\n",
    "path1=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/dev_top1000_cite_pair.pkl\"\n",
    "path2=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/dev_top1000_cite2txt_abs_title_author.pkl\"\n",
    "dumppkl(cite_pair,path1)\n",
    "dumppkl(cite2txt_abs_title_author,path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "577e760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.006386803185438\n"
     ]
    }
   ],
   "source": [
    "len(cite_pair)\n",
    "rst=[]\n",
    "for dp in cite_pair:\n",
    "    rst.append(dp['value'])\n",
    "print(np.mean(rst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aae5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/train_top1000_cite_pair.pkl\"\n",
    "path2=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/train_top1000_cite2txt_abs_title_author.pkl\"\n",
    "cite2txt_abs_title_author=loadpkl(path2)\n",
    "cite_pair=loadpkl(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e781624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151773\n",
      "8721000\n"
     ]
    }
   ],
   "source": [
    "print(len(cite2txt_abs_title_author))\n",
    "print(len(cite_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33dc0763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '8ecf5a8459b8a8767a2123294fd6fc1778b2d39c',\n",
       " 'key': 'eb6eca24a6a5fd913614adb6bcd641aa6f854891',\n",
       " 'value': 6}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_pair[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f89404ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/dev_top1000_cite_pair.pkl\"\n",
    "path2=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml-small/dev_top1000_cite2txt_abs_title_author.pkl\"\n",
    "cite2txt_abs_title_author=loadpkl(path2)\n",
    "cite_pair=loadpkl(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95f5012f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'cd46a80ce754dfa497e46477f9589e81b9ac9df4',\n",
       " 'key': '983265d0fe0ba349ec74d6d8e23e7381a9e32e2c',\n",
       " 'value': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_pair[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44efff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_generate(data):\n",
    "    para=\"\"\n",
    "    para+=data['title']+'[SEP]'\n",
    "    authortxt=' and '.join([item['name'] for item in data['authors']])\n",
    "    para+=authortxt+'[SEP]'\n",
    "    para+=data['abstract']\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffbd866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e1b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(cite2txt_abs_title_author.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "445c3f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal Verification of Robustness and Resilience of Learning-Enabled State Estimation Systems for Robotics[SEP]Wei Huang and Yifan Zhou and Youcheng Sun and Alec Banks and Jie Meng and James Sharp and S. Maskell and Xiaowei Huang[SEP]This paper presents a formal verification guided approach for a principled design and implementation of robust and resilient learning-enabled systems. We focus on learning-enabled state estimation systems (LE-SESs), which have been widely used in robotics applications to determine the current state (e.g., location, speed, direction, etc.) of a complex system. The LE-SESs are networked systems composed of a set of connected components including Bayes filters for localisation, and neural networks for processing sensory input. We study LE-SESs from the perspective of formal verification, which determines the satisfiability of a system model against the specified properties. Over LE-SESs, we investigate two key properties - robustness and resilience - and provide their formal definitions. To enable formal verification, we reduce the LE-SESs to a novel class of labelled transition systems, named {PO}2-LTS in the paper, and formally express the properties as constrained optimisation objectives. We prove that the robustness verification is NP-complete. Based on {PO}2-LTS and the optimisation objectives, practical verification algorithms are developed to check the satisfiability of the properties on the LE-SESs. As a major case study, we interrogate a real-world dynamic tracking system which uses a single Kalman Filter (KF) - a special case of Bayes filter - to localise and track a ground vehicle. Its perception system, based on convolutional neural networks, processes a high-resolution Wide Area Motion Imagery (WAMI) data stream. Experimental results show that our algorithms can not only verify the properties of the WAMI tracking system but also provide representative examples, the latter of which inspired us to take an enhanced LE-SESs design where runtime monitors or joint-KFs are required. Experimental results confirm the improvement of the robustness of the enhanced design.\n"
     ]
    }
   ],
   "source": [
    "print(txt_generate(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217f3da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for k in train_data:\n",
    "    data= cite2txt_abs_title_author[k]\n",
    "    _inputs = tokenizer.encode_plus(\n",
    "            txt_generate(data),\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "#             max_length=512,\n",
    "#             padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=False,\n",
    "        )\n",
    "    if len(_inputs['input_ids'])>512:\n",
    "        cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fea29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
