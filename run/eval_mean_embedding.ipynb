{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4857dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os, sys\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b614af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8eb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        rst=pickle.load(f)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fe8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/data/refsum-data/arxiv-aiml/full_data_no_embed.pkl\"\n",
    "full_data=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/test_result/eval_key_id2embed.pkl\"\n",
    "key_embedding=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3fb80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_test_pred_1000.pkl\"\n",
    "pred_set=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d9263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/share/data/mei-work/kangrui/github/ssref/result/pretrained_pair_sbert/f1_result/eval_test_gold.pkl\"\n",
    "gold_set=loadpkl(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33819b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id2embedding=key_embedding\n",
    "key_id2embedding=key_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b5144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_set={}\n",
    "candidate_ref_set={}\n",
    "for k,v in pred_set.items():\n",
    "    cur=set()\n",
    "    for paper in v[:200]:\n",
    "        cur.add(paper)\n",
    "        refset=set()\n",
    "        for ref in full_data[paper][\"references\"]:\n",
    "            cur.add(ref[\"paperId\"])\n",
    "            refset.add(ref[\"paperId\"])\n",
    "        candidate_ref_set[paper]=refset\n",
    "    candidate_set[k]=list(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b9e03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_pop(candidate_set,candidate_ref_set,rerank_num=None):\n",
    "    query=list(candidate_set.keys())\n",
    "    rerank_candidate={}\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        cite_frequency={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cite_frequency.keys():\n",
    "                            cite_frequency[ref]=1\n",
    "                        else:\n",
    "                            cite_frequency[ref]+=1\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cite_frequency.keys():\n",
    "                cite_frequency[candidate]=1\n",
    "            else:\n",
    "                cite_frequency[candidate]+=1\n",
    "                \n",
    "        top_k = sorted(cite_frequency.items(), key=lambda x:x[1], reverse=True)\n",
    "        rerank = [k for k,v in top_k[:rerank_num]]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "        \n",
    "def rerank_og(candidate_set,query_id2embedding,key_id2embedding,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        key_embedding=[]\n",
    "        for paper in candidate_set[query_paper]:\n",
    "            try:\n",
    "                key_embedding.append(torch.tensor(key_id2embedding[paper]))\n",
    "            except:\n",
    "                key_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "        \n",
    "def rerank_sum(candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        \n",
    "        cited_dict={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            \n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cited_dict.keys():\n",
    "                            cited_dict[ref]=[candidate]\n",
    "                        else:\n",
    "                            cited_dict[ref].append(candidate)\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cited_dict.keys():\n",
    "                cited_dict[candidate]=[candidate]\n",
    "            else:\n",
    "                cited_dict[candidate].append(candidate)\n",
    "                \n",
    "                \n",
    "        key_embedding=[]\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            candidate_embedding=[]\n",
    "            for paper in cited_dict[candidate]:\n",
    "                if paper in key_id2embedding:\n",
    "                    candidate_embedding.append(torch.tensor(key_id2embedding[paper]))\n",
    "            if len(candidate_embedding)==0:\n",
    "                candidate_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "            candidate_embedding=torch.sum(torch.stack(candidate_embedding),dim=0)\n",
    "            \n",
    "            key_embedding.append(candidate_embedding)\n",
    "        \n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "    \n",
    "def rerank_mean(candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,rerank_num=None,device=None):\n",
    "    cnt=0\n",
    "    pbar = tqdm(range(0,len(candidate_set),1), postfix=f\"calculating f1\")\n",
    "    query=list(candidate_set.keys())\n",
    "    empty_embed=torch.tensor(np.zeros_like(next(iter(key_id2embedding.values()))))\n",
    "    empty_embed_cnt=0\n",
    "    if rerank_num is None:\n",
    "        for v in candidate_set.values():\n",
    "            if rerank_num is None or rerank_num>len(v):\n",
    "                rerank_num=len(v)\n",
    "                \n",
    "    rerank_candidate={}   \n",
    "    for i in pbar:\n",
    "        query_paper=query[i]\n",
    "        query_embedding=torch.tensor(query_id2embedding[query_paper]).unsqueeze(0)\n",
    "        \n",
    "        cited_dict={}\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            \n",
    "            if candidate in candidate_ref_set.keys():\n",
    "                # this is possibly the anchor paper\n",
    "                for ref in list(candidate_ref_set[candidate]):\n",
    "                    # deal with the ref of an anchor paper\n",
    "                    if ref in candidate_set[query_paper]:\n",
    "                        if ref not in cited_dict.keys():\n",
    "                            cited_dict[ref]=[candidate]\n",
    "                        else:\n",
    "                            cited_dict[ref].append(candidate)\n",
    "                    else:\n",
    "                        # this is not anchor paper for this query\n",
    "                        break\n",
    "            if candidate not in cited_dict.keys():\n",
    "                cited_dict[candidate]=[candidate]\n",
    "            else:\n",
    "                cited_dict[candidate].append(candidate)\n",
    "                \n",
    "                \n",
    "        key_embedding=[]\n",
    "        for candidate in candidate_set[query_paper]:\n",
    "            candidate_embedding=[]\n",
    "            for paper in cited_dict[candidate]:\n",
    "                if paper in key_id2embedding:\n",
    "                    candidate_embedding.append(torch.tensor(key_id2embedding[paper]))\n",
    "            if len(candidate_embedding)==0:\n",
    "                candidate_embedding.append(empty_embed)\n",
    "                empty_embed_cnt+=1\n",
    "            candidate_embedding=torch.mean(torch.stack(candidate_embedding),dim=0)\n",
    "            \n",
    "            key_embedding.append(candidate_embedding)\n",
    "        \n",
    "        \n",
    "        key_embedding=torch.stack(key_embedding)\n",
    "        query_embedding=query_embedding.to(device)\n",
    "        key_embedding=key_embedding.to(device)\n",
    "        pred_logits=torch.mm(query_embedding,key_embedding.T)\n",
    "        top_k=torch.topk(pred_logits[0],k=rerank_num)[1]\n",
    "#         print(pred_logits[0][top_k[-5:]])\n",
    "        rerank=[candidate_set[query_paper][idx.cpu().item()] for idx in top_k]\n",
    "        rerank_candidate[query_paper]=rerank\n",
    "    print(\"empty embedding cnt->\",empty_embed_cnt)\n",
    "    print(\"min rerank num->\",rerank_num)\n",
    "    return rerank_candidate\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4814628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66aeaf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 944/944 [11:24<00:00,  1.38it/s, calculating f1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty embedding cnt-> 0\n",
      "min rerank num-> 1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rerank_candidate=rerank_mean(candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f2ac9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/share/data/mei-work/kangrui/github/ssref\")\n",
    "from utils.test_utils import *\n",
    "from utils.utils import *\n",
    "def show_rerank_rst(rerank_candidate,gold_set):\n",
    "    pool_length=len(next(iter(rerank_candidate.values())))\n",
    "    i=2\n",
    "    while 1:\n",
    "        all_pred_topN=[]\n",
    "        all_gold=[]\n",
    "        for query_paper,paperlist in rerank_candidate.items():\n",
    "            topN=paperlist[:i]\n",
    "            all_pred_topN.append(topN)\n",
    "            all_gold.append(gold_set[query_paper])\n",
    "        all_pred_topN=np.array(all_pred_topN)\n",
    "        metric = get_precision_recall_f1(all_pred_topN, all_gold)\n",
    "        print(f\"top{i}:\\n{metric}\")\n",
    "        if i>pool_length:\n",
    "            break\n",
    "        i*=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c1a2343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top2:\n",
      "{'precision': 0.1228813559322034, 'recall': 0.0060353798126951096, 'f1': 0.011505653640150763, 'true_pos': 232, 'false_pos': 1656, 'false_neg': 38208, 'num_sample': 944}\n",
      "top4:\n",
      "{'precision': 0.10699152542372882, 'recall': 0.010509885535900104, 'f1': 0.01913966268713284, 'true_pos': 404, 'false_pos': 3372, 'false_neg': 38036, 'num_sample': 944}\n",
      "top8:\n",
      "{'precision': 0.08990995762711865, 'recall': 0.01766389177939646, 'f1': 0.029526874238998083, 'true_pos': 679, 'false_pos': 6873, 'false_neg': 37761, 'num_sample': 944}\n",
      "top16:\n",
      "{'precision': 0.07660222457627118, 'recall': 0.03009885535900104, 'f1': 0.04321679366502316, 'true_pos': 1157, 'false_pos': 13947, 'false_neg': 37283, 'num_sample': 944}\n",
      "top32:\n",
      "{'precision': 0.06620762711864407, 'recall': 0.05202913631633715, 'f1': 0.058268267101736396, 'true_pos': 2000, 'false_pos': 28208, 'false_neg': 36440, 'num_sample': 944}\n",
      "top64:\n",
      "{'precision': 0.05950410487288135, 'recall': 0.09352237252861602, 'f1': 0.07273205470583473, 'true_pos': 3595, 'false_pos': 56821, 'false_neg': 34845, 'num_sample': 944}\n",
      "top128:\n",
      "{'precision': 0.05491922669491525, 'recall': 0.17263267429760665, 'f1': 0.08332914762167863, 'true_pos': 6636, 'false_pos': 114196, 'false_neg': 31804, 'num_sample': 944}\n",
      "top256:\n",
      "{'precision': 0.046663963188559324, 'recall': 0.293366285119667, 'f1': 0.08052009253705766, 'true_pos': 11277, 'false_pos': 230387, 'false_neg': 27163, 'num_sample': 944}\n",
      "top512:\n",
      "{'precision': 0.033074847722457626, 'recall': 0.41586888657648285, 'f1': 0.061276276046058786, 'true_pos': 15986, 'false_pos': 467342, 'false_neg': 22454, 'num_sample': 944}\n",
      "top1024:\n",
      "{'precision': 0.02142333984375, 'recall': 0.538735691987513, 'f1': 0.0412080040115571, 'true_pos': 20709, 'false_pos': 945947, 'false_neg': 17731, 'num_sample': 944}\n",
      "top2048:\n",
      "{'precision': 0.013692199446082694, 'recall': 0.6358480749219563, 'f1': 0.026807140381586624, 'true_pos': 24442, 'false_pos': 1760662, 'false_neg': 13998, 'num_sample': 944}\n"
     ]
    }
   ],
   "source": [
    "rerank_candidate=rerank_mean(candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,device=device)\n",
    "show_rerank_rst(rerank_candidate,gold_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f08401e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 944/944 [10:04<00:00,  1.56it/s, calculating f1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty embedding cnt-> 0\n",
      "min rerank num-> 1891\n",
      "top2:\n",
      "{'precision': 0.21716101694915255, 'recall': 0.010665972944849115, 'f1': 0.02033326720888712, 'true_pos': 410, 'false_pos': 1478, 'false_neg': 38030, 'num_sample': 944}\n",
      "top4:\n",
      "{'precision': 0.2640360169491525, 'recall': 0.025936524453694067, 'f1': 0.047233276482850105, 'true_pos': 997, 'false_pos': 2779, 'false_neg': 37443, 'num_sample': 944}\n",
      "top8:\n",
      "{'precision': 0.2680084745762712, 'recall': 0.05265348595213319, 'f1': 0.08801530700991476, 'true_pos': 2024, 'false_pos': 5528, 'false_neg': 36416, 'num_sample': 944}\n",
      "top16:\n",
      "{'precision': 0.23232256355932204, 'recall': 0.09128511966701353, 'f1': 0.13106977439115491, 'true_pos': 3509, 'false_pos': 11595, 'false_neg': 34931, 'num_sample': 944}\n",
      "top32:\n",
      "{'precision': 0.1828654661016949, 'recall': 0.1437044745057232, 'f1': 0.16093695373499592, 'true_pos': 5524, 'false_pos': 24684, 'false_neg': 32916, 'num_sample': 944}\n",
      "top64:\n",
      "{'precision': 0.13423596398305085, 'recall': 0.21097814776274715, 'f1': 0.16407704135307924, 'true_pos': 8110, 'false_pos': 52306, 'false_neg': 30330, 'num_sample': 944}\n",
      "top128:\n",
      "{'precision': 0.09282309322033898, 'recall': 0.2917793964620187, 'f1': 0.14084082575719523, 'true_pos': 11216, 'false_pos': 109616, 'false_neg': 27224, 'num_sample': 944}\n",
      "top256:\n",
      "{'precision': 0.06125446901483051, 'recall': 0.3850936524453694, 'f1': 0.1056964556022049, 'true_pos': 14803, 'false_pos': 226861, 'false_neg': 23637, 'num_sample': 944}\n",
      "top512:\n",
      "{'precision': 0.038568011784957626, 'recall': 0.4849375650364204, 'f1': 0.0714532129222183, 'true_pos': 18641, 'false_pos': 464687, 'false_neg': 19799, 'num_sample': 944}\n",
      "top1024:\n",
      "{'precision': 0.02308680647510593, 'recall': 0.5805671175858481, 'f1': 0.04440769836911101, 'true_pos': 22317, 'false_pos': 944339, 'false_neg': 16123, 'num_sample': 944}\n",
      "top2048:\n",
      "{'precision': 0.014162200073497118, 'recall': 0.6576742976066597, 'f1': 0.027727326568484225, 'true_pos': 25281, 'false_pos': 1759823, 'false_neg': 13159, 'num_sample': 944}\n"
     ]
    }
   ],
   "source": [
    "rerank_candidate=rerank_sum(candidate_set,query_id2embedding,key_id2embedding,candidate_ref_set,device=device)\n",
    "show_rerank_rst(rerank_candidate,gold_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "075324df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 944/944 [06:32<00:00,  2.40it/s, calculating f1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min rerank num-> 1891\n",
      "top2:\n",
      "{'precision': 0.18273305084745764, 'recall': 0.008975026014568158, 'f1': 0.01710970045625868, 'true_pos': 345, 'false_pos': 1543, 'false_neg': 38095, 'num_sample': 944}\n",
      "top4:\n",
      "{'precision': 0.24152542372881355, 'recall': 0.02372528616024974, 'f1': 0.04320636725412166, 'true_pos': 912, 'false_pos': 2864, 'false_neg': 37528, 'num_sample': 944}\n",
      "top8:\n",
      "{'precision': 0.2551641949152542, 'recall': 0.050130072840790844, 'f1': 0.08379718211862933, 'true_pos': 1927, 'false_pos': 5625, 'false_neg': 36513, 'num_sample': 944}\n",
      "top16:\n",
      "{'precision': 0.2232521186440678, 'recall': 0.08772112382934444, 'f1': 0.12595248767368894, 'true_pos': 3372, 'false_pos': 11732, 'false_neg': 35068, 'num_sample': 944}\n",
      "top32:\n",
      "{'precision': 0.1771054025423729, 'recall': 0.13917793964620187, 'f1': 0.15586761449714484, 'true_pos': 5350, 'false_pos': 24858, 'false_neg': 33090, 'num_sample': 944}\n",
      "top64:\n",
      "{'precision': 0.1299159163135593, 'recall': 0.20418834547346515, 'f1': 0.15879663348709233, 'true_pos': 7849, 'false_pos': 52567, 'false_neg': 30591, 'num_sample': 944}\n",
      "top128:\n",
      "{'precision': 0.08963685116525423, 'recall': 0.2817637877211238, 'f1': 0.1360063287960219, 'true_pos': 10831, 'false_pos': 110001, 'false_neg': 27609, 'num_sample': 944}\n",
      "top256:\n",
      "{'precision': 0.059077893273305086, 'recall': 0.37140998959417276, 'f1': 0.10194070773712621, 'true_pos': 14277, 'false_pos': 227387, 'false_neg': 24163, 'num_sample': 944}\n",
      "top512:\n",
      "{'precision': 0.036964545815677964, 'recall': 0.46477627471383975, 'f1': 0.06848254396590055, 'true_pos': 17866, 'false_pos': 465462, 'false_neg': 20574, 'num_sample': 944}\n",
      "top1024:\n",
      "{'precision': 0.021814378641419493, 'recall': 0.5485691987513007, 'f1': 0.04196017096874329, 'true_pos': 21087, 'false_pos': 945569, 'false_neg': 17353, 'num_sample': 944}\n",
      "top2048:\n",
      "{'precision': 0.01300540472711954, 'recall': 0.6039542143600416, 'f1': 0.025462505977371534, 'true_pos': 23216, 'false_pos': 1761888, 'false_neg': 15224, 'num_sample': 944}\n"
     ]
    }
   ],
   "source": [
    "rerank_candidate=rerank_pop(candidate_set,candidate_ref_set,rerank_num=None)\n",
    "show_rerank_rst(rerank_candidate,gold_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8047c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 944/944 [00:53<00:00, 17.49it/s, calculating f1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty embedding cnt-> 576703\n",
      "min rerank num-> 1891\n",
      "top2:\n",
      "{'precision': 0.2854872881355932, 'recall': 0.014021852237252861, 'f1': 0.026730807379488193, 'true_pos': 539, 'false_pos': 1349, 'false_neg': 37901, 'num_sample': 944}\n",
      "top4:\n",
      "{'precision': 0.23622881355932204, 'recall': 0.02320499479708637, 'f1': 0.0422588592003032, 'true_pos': 892, 'false_pos': 2884, 'false_neg': 37548, 'num_sample': 944}\n",
      "top8:\n",
      "{'precision': 0.1906779661016949, 'recall': 0.037460978147762745, 'f1': 0.06261958601495912, 'true_pos': 1440, 'false_pos': 6112, 'false_neg': 37000, 'num_sample': 944}\n",
      "top16:\n",
      "{'precision': 0.1428760593220339, 'recall': 0.056139438085327786, 'f1': 0.08060660391453758, 'true_pos': 2158, 'false_pos': 12946, 'false_neg': 36282, 'num_sample': 944}\n",
      "top32:\n",
      "{'precision': 0.10391287076271187, 'recall': 0.08165972944849116, 'f1': 0.09145204521617527, 'true_pos': 3139, 'false_pos': 27069, 'false_neg': 35301, 'num_sample': 944}\n",
      "top64:\n",
      "{'precision': 0.07363943326271187, 'recall': 0.11573881373569199, 'f1': 0.09000971109492596, 'true_pos': 4449, 'false_pos': 55967, 'false_neg': 33991, 'num_sample': 944}\n",
      "top128:\n",
      "{'precision': 0.05035090042372881, 'recall': 0.15827263267429761, 'f1': 0.07639760912150284, 'true_pos': 6084, 'false_pos': 114748, 'false_neg': 32356, 'num_sample': 944}\n",
      "top256:\n",
      "{'precision': 0.03677833686440678, 'recall': 0.23121748178980228, 'f1': 0.0634621426327364, 'true_pos': 8888, 'false_pos': 232776, 'false_neg': 29552, 'num_sample': 944}\n",
      "top512:\n",
      "{'precision': 0.02767478813559322, 'recall': 0.34797086368366287, 'f1': 0.051271829625427395, 'true_pos': 13376, 'false_pos': 469952, 'false_neg': 25064, 'num_sample': 944}\n",
      "top1024:\n",
      "{'precision': 0.018977795617055086, 'recall': 0.4772372528616025, 'f1': 0.036503975739630844, 'true_pos': 18345, 'false_pos': 948311, 'false_neg': 20095, 'num_sample': 944}\n",
      "top2048:\n",
      "{'precision': 0.012981316494725238, 'recall': 0.6028355879292404, 'f1': 0.02541534506433626, 'true_pos': 23173, 'false_pos': 1761931, 'false_neg': 15267, 'num_sample': 944}\n"
     ]
    }
   ],
   "source": [
    "rerank_candidate=rerank_og(candidate_set,query_id2embedding,key_id2embedding,device=device)\n",
    "show_rerank_rst(rerank_candidate,gold_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec3278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
